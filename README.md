# ğŸš€ Fine-Tuning y Despliegue de un Modelo Hugging Face (DeepSeek) en Amazon SageMaker

Este proyecto te permite hacer fine-tuning y desplegar un modelo grande de lenguaje (LLM), como **DeepSeek-R1**, en **Amazon SageMaker**, usando Hugging Face y Text Generation Inference (TGI).

Incluye:
- Entrenamiento personalizado con tus propios datos.
- Almacenamiento del modelo fine-tuneado en S3.
- Despliegue del modelo como endpoint de inferencia.

---

## ğŸ“ Estructura del proyecto

project/
â”‚
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ train.py # Script de entrenamiento que corre dentro de SageMaker
â”‚
â”œâ”€â”€ launch_training.py # Lanza el entrenamiento desde tu mÃ¡quina o Jupyter
â”œâ”€â”€ deploy_model.py # Despliega el modelo (preentrenado o fine-tuneado)
â”œâ”€â”€ interact_with_model.py # Probar IA usando endpoint de SageMaker
â”œâ”€â”€ README.md # Este archivo


---

## âš™ï¸ Requisitos

- Cuenta activa en AWS (con permisos en SageMaker y S3)
- Rol para SageMaker
- Datos en formato JSON alojados en S3
- Python 3.10+
- Dependencias instaladas:

```bash
pip install -r requirements.txt

---

## âš™ï¸ Step by step

1ï¸âƒ£ Ejecuta launch_training.py â†’ Lanza entrenamiento en SageMaker
2ï¸âƒ£ SageMaker ejecuta train.py â†’ Entrena el modelo con tus datos
3ï¸âƒ£ El modelo fine-tuneado se guarda en S3
4ï¸âƒ£ Modifica deploy_model.py â†’ Usa model_data en vez de HF_MODEL_ID
5ï¸âƒ£ Ejecuta deploy_model.py â†’ Despliega el modelo entrenado
6ï¸âƒ£ Usa predictor.predict(...) â†’ Prueba inferencias
